{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ozkP7N3_6OG0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import itertools\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2fc-qq6etJ",
        "outputId": "b1643681-be00-44da-ecfb-d1443d226175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "minv9syTJoft"
      },
      "source": [
        "#Classification Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "O31HlDbv6Rxr"
      },
      "outputs": [],
      "source": [
        "class Models:\n",
        "\n",
        "  def __inint__(self, X_train, y_train, y_test, X_test):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.y_test = y_test\n",
        "    self.X_test = X_test\n",
        "\n",
        "\n",
        "  def LR(self, X_train, y_train, y_test, X_test):\n",
        "    # Create a logistic regression object\n",
        "    clf = LogisticRegression(random_state=0)\n",
        "    # Train the model on the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = clf.predict(X_test)\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "  def GNB(self, X_train, y_train, y_test, X_test):\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    y_pred = gnb.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "    return gnb\n",
        "\n",
        "  def DT(self, X_train, y_train, y_test, X_test):\n",
        "    dt = DecisionTreeClassifier(random_state=42,max_depth=2)\n",
        "    dt.fit(X_train, y_train)\n",
        "    y_pred = dt.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "  def RF(self, X_train, y_train, y_test, X_test):\n",
        "    rfc = RandomForestClassifier(n_estimators=1, random_state=0,max_depth=2)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    y_pred = rfc.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "  def SVC(self, X_train, y_train, y_test, X_test):\n",
        "    # Create an SVM object\n",
        "    svc = SVC(random_state=0)\n",
        "    svc.fit(X_train, y_train)\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = svc.predict(X_test)\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "  def KNN(self, X_train, y_train, y_test, X_test):\n",
        "    # Create a KNN object\n",
        "    knn = KNeighborsClassifier(n_neighbors=65)\n",
        "    knn.fit(X_train, y_train)\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = knn.predict(X_test)\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "\n",
        "  def GB(self, X_train, y_train, y_test, X_test):\n",
        "      # Create a Gradient Boosting object\n",
        "      gb = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "      # Hyperparameters to control accuracy\n",
        "      n_estimators = 40\n",
        "      learning_rate = 0.001\n",
        "      max_depth = 2\n",
        "\n",
        "      gb.set_params(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
        "\n",
        "      gb.fit(X_train, y_train)\n",
        "\n",
        "      # Predict the classes of the testing data\n",
        "      y_pred = gb.predict(X_test)\n",
        "\n",
        "      # Evaluate the model performance\n",
        "      acc = accuracy_score(y_test, y_pred)\n",
        "      print('Accuracy:', acc)\n",
        "\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "      cr = classification_report(y_test, y_pred)\n",
        "      print('Classification Report:\\n', cr)\n",
        "\n",
        "\n",
        "  def ADAB(self, X_train, y_train, y_test, X_test):\n",
        "    # Create an AdaBoost object\n",
        "    ada = AdaBoostClassifier(random_state=0)\n",
        "    ada.fit(X_train, y_train)\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = ada.predict(X_test)\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "  def BAG(self, X_train, y_train, y_test, X_test):\n",
        "    # Usage example\n",
        "    tree_max_depth = 2  # Adjust the max depth of the decision tree as desired (or set it to None for unlimited depth)\n",
        "    n_estimators = 40\n",
        "    # Create a Decision Tree object with specified max_depth (if desired)\n",
        "    tree = DecisionTreeClassifier(max_depth=tree_max_depth, random_state=0)\n",
        "\n",
        "    # Create a Bagging object with specified number of estimators\n",
        "    bag = BaggingClassifier(tree, n_estimators=n_estimators, random_state=0)\n",
        "    bag.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = bag.predict(X_test)\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "\n",
        "  def XGB(self, X_train, y_train, y_test, X_test):\n",
        "        # Usage example\n",
        "    max_depth = 1  # Adjust the maximum depth of each tree in the XGBoost model\n",
        "    learning_rate = 0.001  # Adjust the learning rate of the XGBoost model\n",
        "    n_estimators = 40\n",
        "    # Create an XGBoost object with specified hyperparameters\n",
        "    xgb = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, random_state=0)\n",
        "    xgb.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = xgb.predict(X_test)\n",
        "    \n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def LGB(self, X_train, y_train, y_test, X_test):\n",
        "      # Create a LightGBM object\n",
        "      lgbm = lgb.LGBMClassifier(random_state=0)\n",
        "      lgbm.fit(X_train, y_train)\n",
        "\n",
        "      # Predict the probabilities of the testing data\n",
        "      y_pred_prob = lgbm.predict_proba(X_test)\n",
        "      threshold=0.55\n",
        "      # Apply the threshold to convert probabilities to class labels\n",
        "      y_pred = np.where(y_pred_prob[:, 1] >= threshold, 1, 0)\n",
        "\n",
        "      # Evaluate the model performance\n",
        "      acc = accuracy_score(y_test, y_pred)\n",
        "      print('Accuracy:', acc)\n",
        "\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "      cr = classification_report(y_test, y_pred)\n",
        "      print('Classification Report:\\n', cr)\n",
        "\n",
        "  def CB(self, X_train, y_train, y_test, X_test):\n",
        "      cat = CatBoostClassifier(random_state=0, verbose=0)\n",
        "    \n",
        "      # Hyperparameters to control accuracy\n",
        "      n_estimators = 40\n",
        "      learning_rate = 0.01\n",
        "      depth = 3\n",
        "    \n",
        "      cat.set_params(n_estimators=n_estimators, learning_rate=learning_rate, depth=depth)\n",
        "    \n",
        "      cat.fit(X_train, y_train)\n",
        "\n",
        "      # Predict the classes of the testing data\n",
        "      y_pred = cat.predict(X_test)\n",
        "\n",
        "      # Evaluate the model performance\n",
        "      acc = accuracy_score(y_test, y_pred)\n",
        "      print('Accuracy:', acc)\n",
        "\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "      cr = classification_report(y_test, y_pred)\n",
        "      print('Classification Report:\\n', cr)\n",
        "\n",
        "  def LDA(self, X_train, y_train, y_test, X_test):\n",
        "    # Create a LinearDiscriminantAnalysis object and fit the model to the training data\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    lda.fit(X_train, y_train)\n",
        "    # Predict the classes of the testing data\n",
        "    y_pred = lda.predict(X_test)\n",
        "\n",
        "    # Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "    return lda\n",
        "\n",
        "  def QDA(self, X_train, y_train, y_test, X_test):\n",
        "    #Create a QuadraticDiscriminantAnalysis object\n",
        "    qda = QuadraticDiscriminantAnalysis()\n",
        "    #Train the model on the training data\n",
        "    qda.fit(X_train, y_train)\n",
        "\n",
        "    #Predict the classes of the testing data\n",
        "    y_pred = qda.predict(X_test)\n",
        "    #Evaluate the model performance\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "    cr = classification_report(y_test, y_pred)\n",
        "    print('Classification Report:\\n', cr)\n",
        "\n",
        "\n",
        "    return qda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "LLqWBjE8RpQ6"
      },
      "outputs": [],
      "source": [
        "#Making object of the class Models\n",
        "model = Models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GGWLgJLfKY58"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess(df,target):\n",
        "  # Split the data into input features (X) and target variable (y)\n",
        "  X = df.drop(target, axis=1)  # Input features\n",
        "  y = df[target]  # Target variable\n",
        "  # Convert the target variable to numeric values using label encoding\n",
        "  le = LabelEncoder()\n",
        "  y = le.fit_transform(y)\n",
        "  cat_cols = X.select_dtypes(include=['category','object']).columns.tolist()\n",
        "\n",
        "  print(cat_cols)\n",
        "  # Convert categorical features into numerical values using one-hot encoding\n",
        "  categorical_cols = cat_cols\n",
        "  ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "  X_cat = pd.DataFrame(ohe.fit_transform(X[categorical_cols]))\n",
        "  X_cat.columns = ohe.get_feature_names_out(categorical_cols)\n",
        "  X_num = X.drop(categorical_cols, axis=1)\n",
        "  X = pd.concat([X_num, X_cat], axis=1)\n",
        "  # Split data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "  print(\"Shape of training split: \", X_train.shape)\n",
        "  print(\"Shape of test split: \", X_test.shape)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test,X,categorical_cols,ohe,le"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem4=pd.read_csv('/content/sem4new.csv')"
      ],
      "metadata": {
        "id": "O6rDznKZ4SlG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TnS0CoGQ40Gm",
        "outputId": "70f5095d-92d6-43b2-e540-abefc81b182a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0   1   2  3    4   5   6   7  8   9  ...  54  55  56   57     58  59  \\\n",
              "0    36  24  24  0   84   A   8  32  P  40  ...  10  30   P  529  66.13   0   \n",
              "1    29  29  19  0   77   A   8  32  P  30  ...  10  30   P  566  70.75   0   \n",
              "2    37  30  24  0   91  A+   9  36  P  49  ...  10  30   P  633  79.13   0   \n",
              "3    61  30  25  0  116   O  10  40  P  38  ...  10  30   P  645  80.63   0   \n",
              "4    55  25  13  0   93  A+   9  36  P  37  ...   9  27   P  565  70.63   0   \n",
              "..   ..  ..  .. ..  ...  ..  ..  .. ..  ..  ...  ..  ..  ..  ...    ...  ..   \n",
              "395  46  26  24  0   96  A+   9  36  P  46  ...  10  30   P  698  87.25   0   \n",
              "396  28  29  18  0   75   A   8  32  P  29  ...  10  30   P  558  69.75   0   \n",
              "397  28  19  18  0   65   B   6  24  P  28  ...  10  30   P  497  62.13   0   \n",
              "398  56  23  22  0  101   O  10  40  P  45  ...   9  27   P  591  73.88   0   \n",
              "399  45  15  16  0   76   A   8  32  P  34  ...   7  21   P  505  63.13   0   \n",
              "\n",
              "      60    61     62  63  \n",
              "0    207  8.28   Pass   A  \n",
              "1    216  8.64   Pass  A+  \n",
              "2    233  9.32   Pass  A+  \n",
              "3    237  9.48   Pass  A+  \n",
              "4    217  8.68   Pass  A+  \n",
              "..   ...   ...    ...  ..  \n",
              "395  242  9.68   Pass   O  \n",
              "396  216  8.64   Pass  A+  \n",
              "397  166  6.64   Fail  B+  \n",
              "398  221  8.84   Pass  A+  \n",
              "399  196  7.84   Pass   A  \n",
              "\n",
              "[400 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a4bb47e-82be-4828-98a2-38d4538ad87e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>A</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>P</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>529</td>\n",
              "      <td>66.13</td>\n",
              "      <td>0</td>\n",
              "      <td>207</td>\n",
              "      <td>8.28</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>A</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>P</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>566</td>\n",
              "      <td>70.75</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>8.64</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>A+</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>P</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>633</td>\n",
              "      <td>79.13</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>9.32</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "      <td>O</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>P</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>645</td>\n",
              "      <td>80.63</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "      <td>9.48</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>A+</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>P</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>P</td>\n",
              "      <td>565</td>\n",
              "      <td>70.63</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>8.68</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>A+</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>P</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>698</td>\n",
              "      <td>87.25</td>\n",
              "      <td>0</td>\n",
              "      <td>242</td>\n",
              "      <td>9.68</td>\n",
              "      <td>Pass</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>A</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>P</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>558</td>\n",
              "      <td>69.75</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>8.64</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>B</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>P</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>497</td>\n",
              "      <td>62.13</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>6.64</td>\n",
              "      <td>Fail</td>\n",
              "      <td>B+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>56</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>O</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>P</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>P</td>\n",
              "      <td>591</td>\n",
              "      <td>73.88</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>8.84</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>45</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>A</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>P</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>P</td>\n",
              "      <td>505</td>\n",
              "      <td>63.13</td>\n",
              "      <td>0</td>\n",
              "      <td>196</td>\n",
              "      <td>7.84</td>\n",
              "      <td>Pass</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 64 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a4bb47e-82be-4828-98a2-38d4538ad87e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a4bb47e-82be-4828-98a2-38d4538ad87e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a4bb47e-82be-4828-98a2-38d4538ad87e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem4.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLcIxk194uuT",
        "outputId": "a9770f1c-1991-41ae-b709-2ac6cbf14b7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "     ..\n",
              "59    0\n",
              "60    0\n",
              "61    0\n",
              "62    0\n",
              "63    0\n",
              "Length: 64, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming your dataset is in a pandas DataFrame called 'df'\n",
        "categorical_columns = sem4.select_dtypes(include=['object']).columns\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for column in categorical_columns:\n",
        "    sem4[column] = label_encoder.fit_transform(sem4[column])\n",
        "\n",
        "# The categorical columns have been label encoded in place\n"
      ],
      "metadata": {
        "id": "l7dOh9TWe8nv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=sem4"
      ],
      "metadata": {
        "id": "bHHJtSsYfe-J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4A9lJ4BU4bno",
        "outputId": "7abd431b-0991-4587-9e87-6f508a7a79ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0   1   2  3    4  5   6   7  8   9  ...  54  55  56   57     58  59  \\\n",
              "0    36  24  24  0   84  0   8  32  1  40  ...  10  30   0  529  66.13   0   \n",
              "1    29  29  19  0   77  0   8  32  1  30  ...  10  30   0  566  70.75   0   \n",
              "2    37  30  24  0   91  1   9  36  1  49  ...  10  30   0  633  79.13   0   \n",
              "3    61  30  25  0  116  7  10  40  1  38  ...  10  30   0  645  80.63   0   \n",
              "4    55  25  13  0   93  1   9  36  1  37  ...   9  27   0  565  70.63   0   \n",
              "..   ..  ..  .. ..  ... ..  ..  .. ..  ..  ...  ..  ..  ..  ...    ...  ..   \n",
              "395  46  26  24  0   96  1   9  36  1  46  ...  10  30   0  698  87.25   0   \n",
              "396  28  29  18  0   75  0   8  32  1  29  ...  10  30   0  558  69.75   0   \n",
              "397  28  19  18  0   65  2   6  24  1  28  ...  10  30   0  497  62.13   0   \n",
              "398  56  23  22  0  101  7  10  40  1  45  ...   9  27   0  591  73.88   0   \n",
              "399  45  15  16  0   76  0   8  32  1  34  ...   7  21   0  505  63.13   0   \n",
              "\n",
              "      60    61  62  63  \n",
              "0    207  8.28   0   0  \n",
              "1    216  8.64   0   1  \n",
              "2    233  9.32   0   1  \n",
              "3    237  9.48   0   1  \n",
              "4    217  8.68   0   1  \n",
              "..   ...   ...  ..  ..  \n",
              "395  242  9.68   2   7  \n",
              "396  216  8.64   2   1  \n",
              "397  166  6.64   1   3  \n",
              "398  221  8.84   2   1  \n",
              "399  196  7.84   2   0  \n",
              "\n",
              "[400 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f430bd94-b6c2-4978-af92-23da0b0baca4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>529</td>\n",
              "      <td>66.13</td>\n",
              "      <td>0</td>\n",
              "      <td>207</td>\n",
              "      <td>8.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>566</td>\n",
              "      <td>70.75</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>8.64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>633</td>\n",
              "      <td>79.13</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>9.32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>645</td>\n",
              "      <td>80.63</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "      <td>9.48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>565</td>\n",
              "      <td>70.63</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>8.68</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>46</td>\n",
              "      <td>26</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>698</td>\n",
              "      <td>87.25</td>\n",
              "      <td>0</td>\n",
              "      <td>242</td>\n",
              "      <td>9.68</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>558</td>\n",
              "      <td>69.75</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>8.64</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>497</td>\n",
              "      <td>62.13</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>6.64</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>56</td>\n",
              "      <td>23</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>591</td>\n",
              "      <td>73.88</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>8.84</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>45</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>505</td>\n",
              "      <td>63.13</td>\n",
              "      <td>0</td>\n",
              "      <td>196</td>\n",
              "      <td>7.84</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 64 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f430bd94-b6c2-4978-af92-23da0b0baca4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f430bd94-b6c2-4978-af92-23da0b0baca4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f430bd94-b6c2-4978-af92-23da0b0baca4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem4= sem4.drop_duplicates()"
      ],
      "metadata": {
        "id": "HfeVOW5a_NMc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem4['63']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvfKnGG7cbmB",
        "outputId": "2f37fdc1-4ad4-4196-b035-859b3f9c8e19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "395    7\n",
              "396    1\n",
              "397    3\n",
              "398    1\n",
              "399    0\n",
              "Name: 63, Length: 400, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#checking the number of entries per label"
      ],
      "metadata": {
        "id": "UHZeSnB8fHQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    y = sem4['63']\n",
        "    \n",
        "    # Count the number of samples in each class\n",
        "    class_counts = y.value_counts()\n",
        "    print(class_counts)\n",
        "    # Check if any class has only one sample\n",
        "    classes_with_single_sample = [class_label for class_label, count in class_counts.items() if count == 1]\n",
        "    \n",
        "    # Handle classes with a single sample\n",
        "    for class_label in classes_with_single_sample:\n",
        "        # Find the index of the class with a single sample\n",
        "        index = y[y == class_label].index[0]\n",
        "        \n",
        "        # Find the label that is above the class with one sample\n",
        "        above_label = class_counts[class_counts.index > class_label].index.min()\n",
        "        \n",
        "        # Update the target label to the above label\n",
        "        y.loc[index] = above_label\n",
        "\n",
        "        # Count the number of samples in each class\n",
        "    class_counts = y.value_counts()\n",
        "    print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEQa02d_gxv0",
        "outputId": "165c26d6-52ad-4fae-f8ab-470fd55fb5d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    182\n",
            "0    108\n",
            "7     58\n",
            "3     35\n",
            "2     11\n",
            "5      4\n",
            "6      1\n",
            "4      1\n",
            "Name: 63, dtype: int64\n",
            "1    182\n",
            "0    108\n",
            "7     59\n",
            "3     35\n",
            "2     11\n",
            "5      5\n",
            "Name: 63, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "1b2Cb6RskhQ_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sem4['63'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dClqvGu1ne5y",
        "outputId": "ecde028c-31d7-492b-999d-728f8c71d7d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 7, 3, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "\n",
        "# Oversampling the data with a specific sampling strategy\n",
        "smote = SMOTE(random_state=101, k_neighbors=4) \n",
        "X, y = smote.fit_resample(sem4.drop('63', axis=1), sem4['63'])\n",
        "\n",
        "# Creating a new Oversampling DataFrame\n",
        "sem4os = pd.DataFrame(X, columns=df3.drop('63', axis=1).columns)\n",
        "sem4os['63'] = y\n",
        "\n",
        "sns.countplot(sem4os['63'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "2bFbP2WzqCOl",
        "outputId": "e9251946-9b4e-4d19-8137-37605047c666"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem4os['63'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7U6s6_Yn2qJ",
        "outputId": "d4058b8e-926b-4e17-efa8-11d6154ffe43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    182\n",
              "1    182\n",
              "7    182\n",
              "3    182\n",
              "2    182\n",
              "5    182\n",
              "Name: 63, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAking each label to habe 1000 samples using smote"
      ],
      "metadata": {
        "id": "SKNnMmbdfQEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = '63'"
      ],
      "metadata": {
        "id": "eNJDWz2ufNdj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "import seaborn as sns\n",
        "\n",
        "# Perform ADASYN oversampling\n",
        "adasyn = ADASYN(sampling_strategy='not majority', random_state=101,n_neighbors = 4)\n",
        "X, y = adasyn.fit_resample(sem4.drop(target, axis=1), sem4[target])\n",
        "\n",
        "# Create a new oversampled DataFrame\n",
        "sem4os = pd.DataFrame(X, columns=sem4.drop(target, axis=1).columns)\n",
        "sem4os[target] = y\n",
        "\n",
        "# Check the class distribution\n",
        "sns.countplot(sem4os[target])\n",
        "\n",
        "# Ensure each label has 1000 rows\n",
        "label_counts = sem4os[target].value_counts()\n",
        "for label in label_counts.index:\n",
        "    label_rows = sem4os[sem4os[target] == label].shape[0]\n",
        "    if label_rows < 1000:\n",
        "        additional_rows_needed = 1000 - label_rows\n",
        "        label_samples = sem4os[sem4os[target] == label].sample(additional_rows_needed, replace=True)\n",
        "        sem4os = pd.concat([sem4os, label_samples], ignore_index=True)\n",
        "\n",
        "# Check the updated class distribution\n",
        "sns.countplot(sem4os[target])\n",
        "\n",
        "# Save the oversampled data\n",
        "sem4os.to_csv('oversampled_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PMkCoNfmkMZ4",
        "outputId": "a44465ab-de36-4b55-ef57-b644d121dccb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sem4os['63'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92784596-8596-402b-c388-9fafbce04f04",
        "id": "gt-z9tfooq9k"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1000\n",
              "1    1000\n",
              "7    1000\n",
              "3    1000\n",
              "2    1000\n",
              "5    1000\n",
              "Name: 63, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SEM 4"
      ],
      "metadata": {
        "id": "NQUCLBR_KF4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = '63'"
      ],
      "metadata": {
        "id": "2mE90uwDKFtx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test,X,categorical_cols,ohe,le = preprocess(sem4os,target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEwRoh4fMEkn",
        "outputId": "1eb9adad-6134-4516-edef-b7a55fb45baf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "Shape of training split:  (4800, 63)\n",
            "Shape of test split:  (1200, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.BAG(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6eJ_tmzpMIi",
        "outputId": "6814b0f2-0dca-4d45-8376-6293f526fa23"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8416666666666667\n",
            "Confusion Matrix:\n",
            " [[189   0   0   0   0   0]\n",
            " [  0 218   0   0   0   0]\n",
            " [  0   0 204   0   0   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  4 173   5   8   0   9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       189\n",
            "           1       0.56      1.00      0.72       218\n",
            "           2       0.98      1.00      0.99       204\n",
            "           3       0.96      1.00      0.98       179\n",
            "           4       1.00      1.00      1.00       211\n",
            "           5       1.00      0.05      0.09       199\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.91      0.84      0.79      1200\n",
            "weighted avg       0.91      0.84      0.79      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.XGB(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exIDfdhqpus1",
        "outputId": "137d68e9-4cb4-4543-eb29-6a4ea42e58e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9708333333333333\n",
            "Confusion Matrix:\n",
            " [[189   0   0   0   0   0]\n",
            " [  0 218   0   0   0   0]\n",
            " [  0   0 204   0   0   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  4   9   5   8   9 164]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       189\n",
            "           1       0.96      1.00      0.98       218\n",
            "           2       0.98      1.00      0.99       204\n",
            "           3       0.96      1.00      0.98       179\n",
            "           4       0.96      1.00      0.98       211\n",
            "           5       1.00      0.82      0.90       199\n",
            "\n",
            "    accuracy                           0.97      1200\n",
            "   macro avg       0.97      0.97      0.97      1200\n",
            "weighted avg       0.97      0.97      0.97      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.LGB(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym7AqdO2p2hL",
        "outputId": "929604eb-7429-4669-d780-5ae52a33845b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.33916666666666667\n",
            "Confusion Matrix:\n",
            " [[189   0   0   0   0   0]\n",
            " [  0 218   0   0   0   0]\n",
            " [204   0   0   0   0   0]\n",
            " [179   0   0   0   0   0]\n",
            " [211   0   0   0   0   0]\n",
            " [199   0   0   0   0   0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32       189\n",
            "           1       1.00      1.00      1.00       218\n",
            "           2       0.00      0.00      0.00       204\n",
            "           3       0.00      0.00      0.00       179\n",
            "           4       0.00      0.00      0.00       211\n",
            "           5       0.00      0.00      0.00       199\n",
            "\n",
            "    accuracy                           0.34      1200\n",
            "   macro avg       0.20      0.33      0.22      1200\n",
            "weighted avg       0.21      0.34      0.23      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.LR(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "J_mSFrD28Xqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676b2763-16a6-480e-d686-222888cfa459"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8683333333333333\n",
            "Confusion Matrix:\n",
            " [[156  25   1   7   0   0]\n",
            " [ 32 141   0   0   0  45]\n",
            " [  0   0 199   0   0   5]\n",
            " [  1   7   0 168   0   3]\n",
            " [  0   0   0   0 211   0]\n",
            " [  0  25   7   0   0 167]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       189\n",
            "           1       0.71      0.65      0.68       218\n",
            "           2       0.96      0.98      0.97       204\n",
            "           3       0.96      0.94      0.95       179\n",
            "           4       1.00      1.00      1.00       211\n",
            "           5       0.76      0.84      0.80       199\n",
            "\n",
            "    accuracy                           0.87      1200\n",
            "   macro avg       0.87      0.87      0.87      1200\n",
            "weighted avg       0.87      0.87      0.87      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.GNB(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "Gj4tjSdU_kET",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "6ce08069-feaa-4987-9cd7-d74923154392"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.905\n",
            "Confusion Matrix:\n",
            " [[174   0   0  12   0   3]\n",
            " [  6 166   0   0   0  46]\n",
            " [  0   0 174   0  30   0]\n",
            " [  3   0   0 176   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  0   0  14   0   0 185]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.94       189\n",
            "           1       1.00      0.76      0.86       218\n",
            "           2       0.93      0.85      0.89       204\n",
            "           3       0.94      0.98      0.96       179\n",
            "           4       0.88      1.00      0.93       211\n",
            "           5       0.79      0.93      0.85       199\n",
            "\n",
            "    accuracy                           0.91      1200\n",
            "   macro avg       0.91      0.91      0.91      1200\n",
            "weighted avg       0.91      0.91      0.90      1200\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.DT(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "rR5jfrnc_mag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a62480-ed9f-4598-be08-59160ef2675c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5025\n",
            "Confusion Matrix:\n",
            " [[  0   0   0 189   0   0]\n",
            " [  0   0   0 218   0   0]\n",
            " [  0   0 204   0   0   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  0   0   5 185   0   9]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       189\n",
            "           1       0.00      0.00      0.00       218\n",
            "           2       0.98      1.00      0.99       204\n",
            "           3       0.23      1.00      0.38       179\n",
            "           4       1.00      1.00      1.00       211\n",
            "           5       1.00      0.05      0.09       199\n",
            "\n",
            "    accuracy                           0.50      1200\n",
            "   macro avg       0.53      0.51      0.41      1200\n",
            "weighted avg       0.54      0.50      0.41      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.RF(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "pOmj-sNS_okb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4428d79c-42c9-490a-81bc-e8f5a9160afc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5916666666666667\n",
            "Confusion Matrix:\n",
            " [[  0   0   0 154   0  35]\n",
            " [  0   0   0  54   0 164]\n",
            " [  0   0 159  45   0   0]\n",
            " [  0   0  10 165   0   4]\n",
            " [  0   0   0   0 211   0]\n",
            " [  0   0   9   6   9 175]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       189\n",
            "           1       0.00      0.00      0.00       218\n",
            "           2       0.89      0.78      0.83       204\n",
            "           3       0.39      0.92      0.55       179\n",
            "           4       0.96      1.00      0.98       211\n",
            "           5       0.46      0.88      0.61       199\n",
            "\n",
            "    accuracy                           0.59      1200\n",
            "   macro avg       0.45      0.60      0.49      1200\n",
            "weighted avg       0.46      0.59      0.50      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.SVC(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "QvrWUqXL_rAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b913ac-58da-4976-f08a-ca7e9f9042f3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8766666666666667\n",
            "Confusion Matrix:\n",
            " [[161   0   0  28   0   0]\n",
            " [ 29 146   0   0   0  43]\n",
            " [  0   0 187   0  17   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  4   9   5   4   9 168]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       189\n",
            "           1       0.94      0.67      0.78       218\n",
            "           2       0.97      0.92      0.94       204\n",
            "           3       0.85      1.00      0.92       179\n",
            "           4       0.89      1.00      0.94       211\n",
            "           5       0.80      0.84      0.82       199\n",
            "\n",
            "    accuracy                           0.88      1200\n",
            "   macro avg       0.88      0.88      0.87      1200\n",
            "weighted avg       0.88      0.88      0.87      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.KNN(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "CFJ-uHV6_uRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15321133-e1b6-47ce-a15f-047b6a7c9af1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9583333333333334\n",
            "Confusion Matrix:\n",
            " [[178   0   0  11   0   0]\n",
            " [ 14 190   0   0   0  14]\n",
            " [  0   0 202   0   2   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  4   2   0   0   3 190]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       189\n",
            "           1       0.99      0.87      0.93       218\n",
            "           2       1.00      0.99      1.00       204\n",
            "           3       0.94      1.00      0.97       179\n",
            "           4       0.98      1.00      0.99       211\n",
            "           5       0.93      0.95      0.94       199\n",
            "\n",
            "    accuracy                           0.96      1200\n",
            "   macro avg       0.96      0.96      0.96      1200\n",
            "weighted avg       0.96      0.96      0.96      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.GB(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "Yl3dqauy_wsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ef9594-d7f9-4032-f183-910fb333e071"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9791666666666666\n",
            "Confusion Matrix:\n",
            " [[189   0   0   0   0   0]\n",
            " [  0 218   0   0   0   0]\n",
            " [  0   0 204   0   0   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0   0   0 211   0]\n",
            " [  4   9   4   8   0 174]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       189\n",
            "           1       0.96      1.00      0.98       218\n",
            "           2       0.98      1.00      0.99       204\n",
            "           3       0.96      1.00      0.98       179\n",
            "           4       1.00      1.00      1.00       211\n",
            "           5       1.00      0.87      0.93       199\n",
            "\n",
            "    accuracy                           0.98      1200\n",
            "   macro avg       0.98      0.98      0.98      1200\n",
            "weighted avg       0.98      0.98      0.98      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.ADAB(X_train,y_train,y_test,X_test)"
      ],
      "metadata": {
        "id": "p7BfjuoY_yzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea4bb81-4a72-462c-8318-14fa78b21c72"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7683333333333333\n",
            "Confusion Matrix:\n",
            " [[182   0   0   0   0   7]\n",
            " [143   0   0   0   0  75]\n",
            " [  0   0 204   0   0   0]\n",
            " [  0   0   0 179   0   0]\n",
            " [  0   0  50   0 161   0]\n",
            " [  0   0   3   0   0 196]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.96      0.71       189\n",
            "           1       0.00      0.00      0.00       218\n",
            "           2       0.79      1.00      0.89       204\n",
            "           3       1.00      1.00      1.00       179\n",
            "           4       1.00      0.76      0.87       211\n",
            "           5       0.71      0.98      0.82       199\n",
            "\n",
            "    accuracy                           0.77      1200\n",
            "   macro avg       0.68      0.79      0.71      1200\n",
            "weighted avg       0.67      0.77      0.70      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGRhA0mzWd53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}